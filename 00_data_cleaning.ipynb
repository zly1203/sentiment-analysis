{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 1: Configuration\n",
    "#\n",
    "# Set the source file and project name.\n",
    "# The cleaned output will be saved to:\n",
    "#   01_raw_inbox/{PROJECT_NAME}/raw.csv\n",
    "# ==========================================\n",
    "\n",
    "# -- Choose your source file --\n",
    "SOURCE_FILE = \"01_raw_inbox/cold_start/raw.csv\"\n",
    "\n",
    "# -- Project name (matches NB01 PROJECT_NAME) --\n",
    "PROJECT_NAME = \"cold_start\"\n",
    "\n",
    "# -- Optional: sample N rows (set to None for full dataset) --\n",
    "SAMPLE_N = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 01_raw_inbox/cold_start/raw.csv\n",
      "  Shape: (1000, 5)\n",
      "  Columns: ['Unnamed: 0.1', 'Unnamed: 0', 'id', 'sentiment', 'text']\n",
      "  Dropped index artifacts: ['unnamed: 0.1', 'unnamed: 0']\n",
      "\n",
      "--- Cleaning Summary ---\n",
      "  Empty text dropped:  10\n",
      "  Duplicates dropped:  8\n",
      "  Final rows:          982\n",
      "  Final columns:       ['id', 'sentiment', 'text']\n",
      "  Saved to:            ./01_raw_inbox/cold_start/raw.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 2: Load, Clean & Save\n",
    "#\n",
    "# Steps:\n",
    "#   1. Read source CSV\n",
    "#   2. Normalize column names (lowercase, strip whitespace)\n",
    "#   3. Auto-detect text column from known aliases\n",
    "#   4. Drop pandas index artifacts (Unnamed: columns)\n",
    "#   5. Drop rows with empty/NaN text\n",
    "#   6. Deduplicate on text (keep last)\n",
    "#   7. Strip whitespace from all string columns\n",
    "#   8. Optional: random sample\n",
    "#   9. Save to 01_raw_inbox/{PROJECT_NAME}/raw.csv\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from config import DIRS\n",
    "\n",
    "# -- Accepted text column aliases (DATA_SPEC.md ยง1) --\n",
    "TEXT_ALIASES = [\"text\", \"content\", \"body\", \"comment\", \"review\", \"tweet\"]\n",
    "\n",
    "# -- Load --\n",
    "df = pd.read_csv(SOURCE_FILE)\n",
    "print(f\"Loaded: {SOURCE_FILE}\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "\n",
    "# -- Normalize column names --\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "# -- Drop Unnamed index artifacts --\n",
    "unnamed_cols = [c for c in df.columns if c.startswith(\"unnamed\")]\n",
    "if unnamed_cols:\n",
    "    df.drop(columns=unnamed_cols, inplace=True)\n",
    "    print(f\"  Dropped index artifacts: {unnamed_cols}\")\n",
    "\n",
    "# -- Auto-detect and rename text column --\n",
    "text_col = None\n",
    "for alias in TEXT_ALIASES:\n",
    "    if alias in df.columns:\n",
    "        text_col = alias\n",
    "        break\n",
    "\n",
    "if text_col is None:\n",
    "    raise ValueError(\n",
    "        f\"No text column found. Expected one of {TEXT_ALIASES}, \"\n",
    "        f\"got: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "if text_col != \"text\":\n",
    "    df.rename(columns={text_col: \"text\"}, inplace=True)\n",
    "    print(f\"  Renamed '{text_col}' -> 'text'\")\n",
    "\n",
    "# -- Normalize sentiment column if present --\n",
    "if \"sentiment\" in df.columns:\n",
    "    df[\"sentiment\"] = df[\"sentiment\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "# -- Strip whitespace from all string columns --\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# -- Drop empty/NaN text --\n",
    "before = len(df)\n",
    "df = df[df[\"text\"].notna() & (df[\"text\"].str.len() > 0) & (df[\"text\"] != \"nan\")]\n",
    "dropped_empty = before - len(df)\n",
    "\n",
    "# -- Deduplicate on text (keep last) --\n",
    "before = len(df)\n",
    "df.drop_duplicates(subset=[\"text\"], keep=\"last\", inplace=True)\n",
    "dropped_dupes = before - len(df)\n",
    "\n",
    "# -- Optional: random sample --\n",
    "if SAMPLE_N is not None and SAMPLE_N < len(df):\n",
    "    df = df.sample(n=SAMPLE_N, random_state=42)\n",
    "    print(f\"  Sampled {SAMPLE_N} rows (random_state=42)\")\n",
    "\n",
    "# -- Save --\n",
    "output_dir = f\"{DIRS['raw']}/{PROJECT_NAME}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = f\"{output_dir}/raw.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n--- Cleaning Summary ---\")\n",
    "print(f\"  Empty text dropped:  {dropped_empty}\")\n",
    "print(f\"  Duplicates dropped:  {dropped_dupes}\")\n",
    "print(f\"  Final rows:          {len(df)}\")\n",
    "print(f\"  Final columns:       {list(df.columns)}\")\n",
    "print(f\"  Saved to:            {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sentiment-analysis)",
   "language": "python",
   "name": "sentiment-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
